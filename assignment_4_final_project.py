# -*- coding: utf-8 -*-
"""Copy of Assignment_4. Final Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Bxy7L3R1_joemqY8hDG79DTSx3oQsHn_

# Final Project for Machine Learning
## Team Members
* YY - 101------
* GD - 101------
* JW -  101------
* VU - 101------
* David Pinto -  101------

YY - Dataset Set-up
101343887
"""

from keras.datasets import cifar10

(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()

import numpy as np

train_images.shape

test_images.shape

train_labels.shape

test_labels.shape

import matplotlib.pyplot as plt

train_images[0]

train_labels[0]

test_images[0]

test_labels[0]

image = train_images[0]

plt.imshow(image)
plt.show()

image_test = test_images[0]

plt.imshow(image_test)
plt.show()

"""---
## Normalize and convert the labels to categorical type
### JW- 101------
"""

from keras.utils import to_categorical

"""#### X-axis (Images)"""

# Normalize the images from the training and testing datasets by dividing by
# 255 (the RGB color range is 0-255)
#
# TLDR: This allows us to squash/normalize all the values between 0 and 1
train_images = train_images.astype("float32") / 255
test_images = test_images.astype("float32") / 255

"""#### Y-axis (Labels)"""

# Convert the class labels from CIFAR10 (currently integer values) to
# categorical data (one-hot encoded vector)
#
# TLDR: This is required to train our model. 10 represents the number of categories.
train_labels = to_categorical(train_labels, 10)
test_labels = to_categorical(test_labels, 10)

"""## Split dataset into training and testing (create validation dataset)"""

from sklearn.model_selection import train_test_split

# Split by using 30% of the datasets for testing and the 70% left for training.
#
# TLDR: Split our datasets to train and validate our model.
x_train, x_test, y_train, y_test = train_test_split(train_images, train_labels,
                                                    test_size=0.3)

"""#### Training"""

# Display first image of the training dataset
#
# TLDR: Display the RGB color values from the pixels of the first image.
x_train[:1]

# Visualize it
plt.imshow(x_train[0])
plt.show()

# Display first category of the training dataset
#
# TLDR: Display the one-hot encoded representation of the first category.
y_train[0]

"""#### Testing"""

# Display first image of the testing dataset
#
# TLDR: Display the RGB color values from the pixels of the first image.
x_test[:1]

# Visualize it
plt.imshow(x_test[0])
plt.show()

# Display first category of the testing dataset
#
# TLDR: Display the one-hot encoded representation of the first category.
y_test[0]

"""GD 101------
Building a model and fitting
"""

x_train, x_val, y_train, y_val = train_test_split(x_train, y_train,
                                                    test_size=0.2)

from keras import models
from keras import layers
from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout

model = models.Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(32, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(32, (3, 3), activation='relu'))
model.add(Flatten())
model.add(Dense(32, activation='relu'))
model.add(Dense(10, activation='softmax'))

model.summary()

model.compile(optimizer='rmsprop',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

history = model.fit(x_train, y_train, epochs=50, batch_size=256,
                    validation_data=(x_val, y_val))

train_accurancy = history.history['accuracy']
val_accurancy = history.history['val_accuracy']

epochs = range(1, len(train_accurancy) + 1)
plt.plot(epochs, train_accurancy, 'bo', label='Training loss')
plt.plot(epochs, val_accurancy, 'r', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

"""VU 101------
Adding additional convolutional layers
"""

model = models.Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(32, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Flatten())
model.add(Dense(32, activation='relu'))
model.add(Dense(10, activation='softmax'))

model.compile(optimizer='rmsprop',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

history = model.fit(x_train, y_train, epochs=50, batch_size=256,
                    validation_data=(x_val, y_val))

train_acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

epochs = range(1, len(train_acc) + 1)
plt.plot(epochs, train_acc, 'bo', label='Training loss')
plt.plot(epochs, val_acc, 'r', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

"""David Pinto - 101------
Modifing the input shape for convolutional layer
"""

model = models.Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(16, 16, 3)))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(32, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dense(10, activation='softmax'))

model.compile(optimizer='rmsprop',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

history = model.fit(x_train, y_train, epochs=50, batch_size=256,
                    validation_data=(x_val, y_val))

train_acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

epochs = range(1, len(train_acc) + 1)

plt.plot(epochs, train_acc, 'bo', label='Training accuracy')
plt.plot(epochs, val_acc, 'r', label='Validation accuracy')
plt.title('Training and validation accuracy 4')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

#remove first two layers and train again
model.layers.pop(0)
model.layers.pop(0)
for layer in model.layers:
    layer.trainable = True

model.compile(optimizer='rmsprop',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

history = model.fit(x_train, y_train, epochs=50, batch_size=256,
                    validation_data=(x_val, y_val))

train_acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

epochs = range(1, len(train_acc) + 1)
plt.plot(epochs, train_acc, 'bo', label='Training accuracy')
plt.plot(epochs, val_acc, 'r', label='Validation accuracy')
plt.title('Training and validation accuracy 2')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

model.layers.pop(0)
model.layers.pop(0)
for layer in model.layers:
    layer.trainable = True

model.compile(optimizer='rmsprop',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

history = model.fit(x_train, y_train, epochs=50, batch_size=256,
                    validation_data=(x_val, y_val))

train_acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

epochs = range(1, len(train_acc) + 1)

plt.plot(epochs, train_acc, 'bo', label='Training accuracy')
plt.plot(epochs, val_acc, 'r', label='Validation accuracy')
plt.title('Training and validation accuracy 3')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

model.layers.pop(0)
model.layers.pop(0)
model.layers.pop(0)
for layer in model.layers:
    layer.trainable = True

model.compile(optimizer='rmsprop',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

history = model.fit(x_train, y_train, epochs=50, batch_size=256,
                    validation_data=(x_val, y_val))

train_acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

epochs = range(1, len(train_acc) + 1)
plt.plot(epochs, train_acc, 'bo', label='Training accuracy')
plt.plot(epochs, val_acc, 'r', label='Validation accuracy')
plt.title('Training and validation accuracy 4')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

"""YY & JW
Adding dropout layer
"""

model = models.Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(16, 16, 3)))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(32, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5)),
model.add(Dense(10, activation='softmax'))

model.compile(optimizer='rmsprop',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

history = model.fit(x_train, y_train, epochs=50, batch_size=256,
                    validation_data=(x_val, y_val))

train_loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(1, len(train_loss) + 1)
plt.plot(epochs, train_loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'r', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

"""---"""